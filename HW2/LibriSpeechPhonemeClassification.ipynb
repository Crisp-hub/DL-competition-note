{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1954aead",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "## preparing Data and TraingVisualization\n",
    "**助教给的demo code 东西是全塞在一起，注释是基本不给...  \n",
    "HW1和HW2代码可读程度完全不是一个等级呀**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "830b013b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CUDA devices: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "#dataPreprocess\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import random\n",
    "\n",
    "#plotting Tools\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "#seed\n",
    "myseed = 420613\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)\n",
    "device_count = torch.cuda.device_count()\n",
    "print(f\"Number of CUDA devices: {device_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6eb22f",
   "metadata": {},
   "source": [
    "# Some Utilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61fdd5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    '''geting device if cuda is available'''\n",
    "    return 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def plot_learning_curve(loss_record,title = ''):\n",
    "    '''plot learning curve of your DNN()(train&dev loss)'''\n",
    "    total_steps = len(loss_record['train'])\n",
    "    x_1 = range(total_steps)\n",
    "    x_2 = x_1[::len(loss_record['train'])//len(loss_record['dev'])]\n",
    "    figure(figsize=(6,4))\n",
    "    plt.plot(x_1,loss_record['train'],c = 'tab:red', label = 'train')\n",
    "    plt.plot(x_2,loss_record['dev'],c = 'tab:cyan', label = 'dev')\n",
    "    plt.ylim(0.0,5.)\n",
    "    plt.xlabel('TrainSteps')\n",
    "    plt.ylabel('MSE loss')\n",
    "    plt.title('Learning curve of {}'.format(title))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_pred(dv_set, model, device, lim = 35., preds = None, targets = None):\n",
    "    '''plot predition of your DNN'''\n",
    "    if preds is None or targets is None:\n",
    "        model.eval()#set model to eval mode\n",
    "        preds, targets = [], []\n",
    "        for x, y in dv_set:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                preds.append(pred.detach().cpu())\n",
    "                targets.append(y.detach().cpu())\n",
    "        preds = torch.cat(preds, dim = 0).numpy()\n",
    "        targets = torch.cat(targets, dim = 0).numpy()\n",
    "        \n",
    "    figure(figsize=(5,5))\n",
    "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
    "    plt.plot([-0.2,lim], [-0.2, lim], c = 'b')\n",
    "    plt.xlim(-0.2,lim)\n",
    "    plt.ylim(-0.2,lim)\n",
    "    plt.xlabel('ground truth value')\n",
    "    plt.ylabel('predicted value')\n",
    "    plt.title('Ground Truth with Prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9141873",
   "metadata": {},
   "source": [
    "**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n",
    "\n",
    "A phoneme may span several frames and is dependent to past and future frames. \\\n",
    "Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n",
    "\n",
    "Feel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides) \n",
    "\n",
    "**下面的Helper函数预处理每个语句的MFCC原始特征训练数据，由于一个音素可以跨越几个帧且对过去和未来的帧具有依赖性  \n",
    "我们对相邻的音素进行训练，以便达到更高的准确性。连接过去和未来的k帧（总共2k+1 = n帧），我们预测中心帧。  \n",
    "可以随意修改预处理函数但不要删除任何帧**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44e6f075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\n",
      "torch.Size([284, 39])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "#由于文件打开不了，我们将文件读一个出来看看大小数据类型分别是什么样子的\n",
    "feat = torch.load('./dataset/libriphone/feat/train/19-198-0008.pt')\n",
    "cur_len = len(feat)\n",
    "print(cur_len)\n",
    "print(feat.shape)\n",
    "print(type(feat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e20fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feature(path):\n",
    "    '''从文件中加载特征'''\n",
    "    feat = torch.load(path)\n",
    "    return feat\n",
    "# def shift(x, n):\n",
    "#     '''\n",
    "#     数据扩展，特征拼接\n",
    "#     将输入张量x向左或向右移动n个距离用边界值填充移动后的空缺位置。\n",
    "#     x：张量 n：移动距离，负为向右移动，反之向左移动\n",
    "#     '''\n",
    "#     if n < 0 :\n",
    "#         right = x[:n]\n",
    "#         left = x[0].repeat(-n, 1)\n",
    "#     elif n > 0:\n",
    "#         right = x[-1].repeat(n, 1)\n",
    "#         left = x[n:]\n",
    "#     else:\n",
    "#         return x\n",
    "#     return torch.cat((left,right), dim = 0)\n",
    "def shift(x, n):\n",
    "    if n < 0:\n",
    "        left = x[0].repeat(-n, 1)\n",
    "        right = x[:n]\n",
    "        # print(left)\n",
    "        # print(right)\n",
    "        # print(\"x[:-1]:\",x[:-1])\n",
    "\n",
    "    elif n > 0:\n",
    "        right = x[-1].repeat(n, 1)\n",
    "        left = x[n:]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "    return torch.cat((left, right), dim=0)\n",
    "# x = torch.tensor([[1,2,3],\n",
    "#                   [4,5,6],\n",
    "#                   [7,8,9],\n",
    "#                   [10,11,12]])\n",
    "# y = shift(x,1)\n",
    "# z = shift(x,-1)\n",
    "# print(\"y:{}\".format(y))\n",
    "# print(\"z:{}\".format(z))\n",
    "\n",
    "def concat_feat(x, concate_n):\n",
    "    '''\n",
    "    x：张量，为直接的特征\n",
    "    concate_n:\n",
    "    '''\n",
    "    assert concate_n % 2 == 1, '拼接数为偶数'\n",
    "    if concate_n < 2 :\n",
    "        return x\n",
    "    seq_len, featrue_dim = x.size(0), x.size(1)\n",
    "    x = x.repeat(1,concate_n)\n",
    "    x = x.view(seq_len, concate_n, featrue_dim).permute(1, 0, 2)\n",
    "    mid = (concate_n // 2)\n",
    "    for r_idx in range(1, mid + 1):\n",
    "        #由中心张量复制出来的两侧张量都向中间靠拢，每离中心向量一格距离则移动一格\n",
    "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)              #右侧张量向左移动\n",
    "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)             #左侧张量向右移动\n",
    "        \n",
    "    return x.permute(1, 0, 2).view(seq_len, featrue_dim*concate_n)   #将处理好的张量拼接回原来的样子\n",
    "\n",
    "def train_label(mode,split,phone_path):\n",
    "    '''\n",
    "    split:模型训练不同阶段train/val/test\n",
    "    phone_path:文件路径\n",
    "    \n",
    "    建立起train_data文件名和label之间的映射，返回字典\n",
    "    '''\n",
    "    label_dict = {}\n",
    "    if mode != 'test':\n",
    "        phone_file = open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines()\n",
    "\n",
    "        for line in phone_file:\n",
    "            line = line.strip('\\n').split(' ')\n",
    "            label_dict[line[0]] = [int(p) for p in line[1:]]\n",
    "    return label_dict\n",
    "\n",
    "def split_train_val(split, phone_path, seed, train_ratio):\n",
    "    '''\n",
    "    split:模型训练不同阶段train/val/test\n",
    "    phone_path:meta文件父路径\n",
    "    seed：随机种子\n",
    "    train_ratio：训练验证集划分比\n",
    "    \n",
    "    将train_data划分为训练集和验证集\n",
    "    '''\n",
    "    if split == 'train' or split == 'val' :\n",
    "        usage_list = open(os.path.join(phone_path,'train_split.txt')).readlines()\n",
    "        random.seed(seed)\n",
    "        random.shuffle(usage_list)\n",
    "        percent = int(len(usage_list) * train_ratio)\n",
    "        \n",
    "        print(percent)\n",
    "        \n",
    "        usage_list = usage_list[:percent] if split == 'train' else usage_list[percent:]\n",
    "    \n",
    "    elif split == 'test':\n",
    "        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n",
    "    else:\n",
    "        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
    "    \n",
    "    usage_list = [line.strip('\\n') for line in usage_list]\n",
    "    print('[Dataset] - # phone classes: ' + str(41) + \n",
    "          ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
    "    \n",
    "    return usage_list\n",
    "\n",
    "def process_feature(split, \n",
    "                    feat_dir, \n",
    "                    concat_nframes, \n",
    "                    label_dict, \n",
    "                    usage_list):\n",
    "    '''\n",
    "    对每个语音（文件名）对应的特征进行根据usagelist来读取对应文件特征，并根据给出的concat_nframes来\n",
    "    判断需要对扩展出几个帧,主要是一些比较杂的判断和处理，比如创建空张量、\n",
    "    '''\n",
    "    mode = 'train' if split == 'train' or split == 'val' else 'test'\n",
    "    #1.创建空张量便于将不同文件中的特征输入到张量中\n",
    "    max_len = 3000000\n",
    "    X = torch.empty(max_len, 39 * concat_nframes)                              #\n",
    "    if mode != 'test' :\n",
    "        y = torch.empty(max_len,dtype=torch.long)\n",
    "    \n",
    "    #2.读取文件\n",
    "    #根据usage_list来选择train/val/test对应的特征，cur_len是每个特征文件的特征向量个数\n",
    "    idx = 0\n",
    "    for i,fname in tqdm(enumerate(usage_list)):\n",
    "        feat = load_feature(os.path.join(feat_dir,mode,f'{fname}.pt'))\n",
    "        \n",
    "        #print(\"从文件{}中加载出来的特征形状，类型：\".format(fname),feat.shape,type(feat))#一个文件中\n",
    "        \n",
    "        cur_len = len(feat)\n",
    "        feat = concat_feat(feat, concat_nframes)\n",
    "        if mode != 'test':\n",
    "            label = torch.LongTensor(label_dict[fname])\n",
    "            \n",
    "        X[idx: idx + cur_len,:] = feat\n",
    "        if mode != 'test':\n",
    "            y[idx: idx + cur_len] = label\n",
    "        \n",
    "        idx += cur_len\n",
    "        \n",
    "    #冗余0张量空间消除，同时做一些不同mode下的判断处理\n",
    "    X = X[:idx, :]\n",
    "    if mode != 'test':\n",
    "        y = y[:idx]\n",
    "        \n",
    "    print(f'[INFO] {split} set')\n",
    "    print(X.shape)\n",
    "    if mode != 'test':\n",
    "        print(y.shape)\n",
    "        return X,y\n",
    "    else:\n",
    "        return X,None                #为了增强代码鲁棒性，在测试集情况下我们将标签读取值同样返回为None这样方便判断\n",
    "    \n",
    "def preprocess_data(split,           #mode：train/val/test\n",
    "                    feat_dir,        #特征父文件夹\n",
    "                    phone_path,      #文件名父文件夹\n",
    "                    concat_nframes,  #拼接数量\n",
    "                    train_ratio,     #训练集验证集划分\n",
    "                    train_val_seed): #随机种子\n",
    "    '''\n",
    "    包含处理数据集输入以及张量拼接的一系列操作，以及train/val划分\n",
    "    '''\n",
    "    class_num = 41\n",
    "    mode = 'train' if split == 'train' or split == 'val' else 'test'          #确定计算模式\n",
    "    \n",
    "    label_dict = train_label(mode=mode,split=split, phone_path=phone_path)              #建立起文件名和标签之间的联系\n",
    "    \n",
    "    usage_list = split_train_val(split=split,                                 #根据模式返回打乱后的数据集/验证集\n",
    "                                 phone_path=phone_path, \n",
    "                                 seed=train_val_seed,\n",
    "                                 train_ratio=train_ratio)\n",
    "    return process_feature(split = split,                                       #根据文件名提取特征，以及concate\n",
    "                    feat_dir = feat_dir,                                      #feat操作，\n",
    "                    concat_nframes = concat_nframes, \n",
    "                    label_dict = label_dict, \n",
    "                    usage_list = usage_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2838f84",
   "metadata": {},
   "source": [
    "**repeat函数参数个数必须 >= 给定张量的维度个数，如果给出的参数数量m大于给定的张量唯独数量n，则\n",
    "优先将 m 个参数中后 n 个参数匹配到张量的维度上进行repeat**\n",
    "**在理解了repeat的基础上就很容易理解上面几个函数的作用**\n",
    "\n",
    "```python\n",
    "view()函数在面对多个参数时的行为也有些难以理解，我们按照将张量展平成1维向量之后再对张量进行处理\n",
    "x:\n",
    "tensor([[ 1,  2,  3],\n",
    "        [ 4,  5,  6],\n",
    "        [ 7,  8,  9],\n",
    "        [10, 11, 12]])\n",
    "展平的数据: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "新张量的形状是 (2, 2, 3)，即 2 个大小为 (2, 3) 的小张量。\n",
    "按照展平的数据顺序依次填充新张量。\n",
    "y:\n",
    "tensor([[[ 1,  2,  3],\n",
    "         [ 4,  5,  6]],\n",
    "        [[ 7,  8,  9],\n",
    "         [10, 11, 12]]])\n",
    "repeat函数举例\n",
    "x:\n",
    "tensor([[ 1,  2],  \n",
    "        [ 3,  4],  \n",
    "        [ 5,  6],  \n",
    "        [ 7,  8],  \n",
    "        [ 9, 10]])  \n",
    "x = x.repeat(1, concat_n)\n",
    "x:  \n",
    "tensor([[ 1,  2,  1,  2,  1,  2],  \n",
    "        [ 3,  4,  3,  4,  3,  4],  \n",
    "        [ 5,  6,  5,  6,  5,  6],  \n",
    "        [ 7,  8,  7,  8,  7,  8],  \n",
    "        [ 9, 10,  9, 10,  9, 10]])  \n",
    "seq_len = 5, concat_n = 3, feature_dim = 2\n",
    "5个大小为3*2的二维向量，相当于把每一行重复的列数值都放在了一个二维向量里\n",
    "再通过permute方法将维度进行重组，调整第一个维度和第二个维度的位置就可以做到\n",
    "将三个重复的向量进行拆分\n",
    "\n",
    "x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2)\n",
    "\n",
    "x.view(seq_len, concat_n, feature_dim):\n",
    "tensor([[[1, 2],\n",
    "         [1, 2],\n",
    "         [1, 2]],\n",
    "        [[3, 4],\n",
    "         [3, 4],\n",
    "         [3, 4]],\n",
    "        [[5, 6],\n",
    "         [5, 6],\n",
    "         [5, 6]],\n",
    "        [[7, 8],\n",
    "         [7, 8],\n",
    "         [7, 8]],\n",
    "        [[9, 10],\n",
    "         [9, 10],\n",
    "         [9, 10]]])\n",
    "官网上并未明说permute函数的具体机制，那么我们来研究一下。得到的结果最直观的表显示上就是\n",
    "不同维度之间的大小被转换了，那么张量里的元素是怎么被分配的呢。经过观察得到的经验是：\n",
    "\n",
    "不同维度之间元素把并没有经过重组，我们对于该三维张量，只是从不同角度来看它们了。\n",
    "想象一个张量立方体，由于我们只能将张量从二维上表现出来。所以从不同角度观察该立方体，\n",
    "即把不同角度作为该立方体的第一个维度，得到的直观上的张量也是不同的。\n",
    "总结上：从不同角度观察得到表现上不同的张量，但这实际上都是为了我们将上下文拼接器来\n",
    "而服务的。只是为了我们的数据处理而服务，对于不同的实际数据还是需要具体发分析\n",
    "\n",
    "x:\n",
    "tensor([[[ 1,  2],\n",
    "         [ 3,  4],\n",
    "         [ 5,  6],\n",
    "         [ 7,  8],\n",
    "         [ 9, 10]],\n",
    "\n",
    "        [[ 1,  2],\n",
    "         [ 3,  4],\n",
    "         [ 5,  6],\n",
    "         [ 7,  8],\n",
    "         [ 9, 10]],\n",
    "\n",
    "        [[ 1,  2],\n",
    "         [ 3,  4],\n",
    "         [ 5,  6],\n",
    "         [ 7,  8],\n",
    "         [ 9, 10]]])\n",
    "\n",
    "concate_feature中的后半部分操作：\n",
    "x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
    "x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
    "\n",
    "shift(x[mid + 1], 1):\n",
    "tensor([[ 3,  4],\n",
    "        [ 5,  6],\n",
    "        [ 7,  8],\n",
    "        [ 9, 10],\n",
    "        [ 9, 10]])\n",
    "\n",
    "shift(x[mid - 1], -1):\n",
    "tensor([[ 1,  2],\n",
    "        [ 1,  2],\n",
    "        [ 3,  4],\n",
    "        [ 5,  6],\n",
    "        [ 7,  8]])\n",
    "\n",
    "最终结果:\n",
    "tensor([[[ 1,  2],\n",
    "         [ 1,  2],\n",
    "         [ 3,  4],\n",
    "         [ 5,  6],\n",
    "         [ 7,  8]],\n",
    "\n",
    "        [[ 1,  2],\n",
    "         [ 3,  4],\n",
    "         [ 5,  6],\n",
    "         [ 7,  8],\n",
    "         [ 9, 10]],\n",
    "\n",
    "        [[ 3,  4],\n",
    "         [ 5,  6],\n",
    "         [ 7,  8],\n",
    "         [ 9, 10],\n",
    "         [ 9, 10]]])\n",
    "result = x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
    "result:\n",
    "！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！重点！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！\n",
    "有没有看出经过操作之后的张量的每一行怎么样了，从第二行开始，我们的位移操作实际上是将与中心音素相差时刻数的音素\n",
    "进行偏移最后拼接起来这样既将前后时序的音素拼接起来了，又将音素特征的大小从39扩充到了39*concat_nframes的大小\n",
    "既使得网络能够考虑到上下文，又增强了模型的输入大小。这里shift + concate的操作真是太妙了。\n",
    "tensor([[ 1,  2,  1,  2,  3,  4],\n",
    "        [ 1,  2,  3,  4,  5,  6],\n",
    "        [ 3,  4,  5,  6,  7,  8],\n",
    "        [ 5,  6,  7,  8,  9, 10],\n",
    "        [ 7,  8,  9, 10,  9, 10]])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2636bb80-8ff8-4921-aaf4-ef7309524669",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 数据预处理核心 \n",
    "经过位移和拼接操作之后的张量的每一行就是不同采样帧之间的拼接，从第二行开始，我们的位移操作实际上是将与中心音素相差时刻数的音素  \n",
    "进行偏移最后拼接起来这样既将前后时序的音素拼接起来了，又将音素特征的大小从39扩充到了39*concat_nframes的大小既使得网络能够\n",
    "考虑到上下文，又增强了模型的输入大小。这里shift + concate的操作真是太妙了。  \n",
    "tensor([  \n",
    "[ 1,  2,  1,  2,  3,  4],  \n",
    "[ 1,  2,  3,  4,  5,  6],  \n",
    "[ 3,  4,  5,  6,  7,  8],  \n",
    "[ 5,  6,  7,  8,  9, 10],  \n",
    "[ 7,  8,  9, 10,  9, 10]  \n",
    "])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350af734",
   "metadata": {},
   "source": [
    "# Dataset & DataLoader\n",
    "**对于示例代码中的代码结构有些粗糙了，将许多步骤分离。应该将数据处理部分的操作都放入继承并实现Dataset的数据类中  \n",
    "这样对于输入文件路径给dataLoader就能够直接返回迭代器。 避免分离处理不同的代码组成部分。  \n",
    "下面将实现把数据文件的读入、预处理等操作集合到自己实现的dataset数据集中**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a21756",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                split,\n",
    "                feat_dir, \n",
    "                phone_path, \n",
    "                concat_nframes, \n",
    "                train_ratio, \n",
    "                train_val_seed):\n",
    "        \n",
    "        self.data, self.label = preprocess_data(split=split,\n",
    "                                            feat_dir=feat_dir,\n",
    "                                            phone_path=phone_path,\n",
    "                                           concat_nframes=concat_nframes,\n",
    "                                            train_ratio=train_ratio,\n",
    "                                            train_val_seed=train_val_seed)\n",
    "        if split == 'train' or split == 'val':\n",
    "            assert self.label != None, 'label为空'                    #断言（若为训练/验证集）label不为空\n",
    "        else :\n",
    "            assert self.label == None, 'label不为空，存在错误'\n",
    "        \n",
    "            \n",
    "    def __getitem__(self,index):\n",
    "        if self.label is not None:\n",
    "            return self.data[index], self.label[index]\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "#DataLoader   \n",
    "def PrepDataloader(split,\n",
    "                   batch_size,\n",
    "                   feat_dir, \n",
    "                   phone_path, \n",
    "                   concat_nframes,\n",
    "                   n_jobs = 0,\n",
    "                   train_ratio = 0.8, \n",
    "                   train_val_seed = 1337):\n",
    "    dataset = SpeechDataset(split=split,\n",
    "                            feat_dir=feat_dir,\n",
    "                            phone_path=phone_path,\n",
    "                            concat_nframes=concat_nframes,\n",
    "                            train_ratio = train_ratio,\n",
    "                            train_val_seed = train_val_seed)\n",
    "    \n",
    "    dataloader = DataLoader(dataset=dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=(split == 'train'),\n",
    "                            num_workers=n_jobs,\n",
    "                            pin_memory=True,\n",
    "                            drop_last=False)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5537805b",
   "metadata": {},
   "source": [
    "# NeuralNetwork\n",
    "**该分类问题一共41个标签类别分别代表41个音素，在模型的输出层设计上需要进行考虑。  \n",
    "这里的模型设计可以使用RNN来处理语音特征，但具体怎么使用还不太清楚  \n",
    "初始模型非常简单，就是两个全连接层外加一个列表表达式中全连接层的堆叠**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d04571ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.Linear(input_dim,output_dim),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256):\n",
    "        super(Classifier,self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            \n",
    "            BasicBlock(input_dim, hidden_dim),\n",
    "            \n",
    "            nn.Dropout(0.2),\n",
    "            ##列表生成式，由于不需要使用序列中的序列值。所以用_来表示\n",
    "            *[BasicBlock(hidden_dim,hidden_dim) if i%2 == 0 else nn.Dropout(0.2) for i in range(hidden_layers*2)],\n",
    "            \n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            \n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    def forward(self,x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "    def cal_loss(self, pred, labels, L2_lambda = 0.0):\n",
    "        crossEntropyLoss = self.criterion(pred, labels)\n",
    "        # L2 regularization：\n",
    "        # l2_reg = 0.0\n",
    "        # if L2_lambda > 0.0:\n",
    "        #     for parm in self.parameters():\n",
    "        #         l2_reg += torch.sum(parm**2)\n",
    "        return crossEntropyLoss #+ l2_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f527e2",
   "metadata": {},
   "source": [
    "# Train/Dev/Test\n",
    "## Training\n",
    "**经验总结**\n",
    "* 1.在处理`loss`（如比较大小，计算平均值，可视化）之前使用变量存储从计算图中分离出来并转化为标量（numpy）的loss值\n",
    "* 2.在分类问题中要提取预测结果中得分最大的类别常用：`_,pred_maxProb_class = torch.max(pred, 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c6391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#用于保存模型，如果每次不全部运行所有代码由于best_acc的全局性可以保证保存的模型在内存不被清除之前是全局最优的\n",
    "def train(tr_set, dev_set, model, config, device):\n",
    "    \n",
    "    #setup optimizer\n",
    "    optimizer = getattr(torch.optim,config['optimizer'])(\n",
    "        model.parameters(),**config['optim_hparas'])\n",
    "    \n",
    "    n_epochs = config['n_epochs']\n",
    "#     min_crossEntropy = 10000                            #在使用早停后可以考虑记录min_crossEntropy的最小值以及\n",
    "#     min_acc = 0                                         #\n",
    "    loss_record = {'train':[], 'dev':[]}                  #记录训练损失并且由于是分类任务还需要计算ACC\n",
    "    acc_record = {'train':[], 'dev':[]}                   #将损失在训练过程可视化有利于模型调参和发现问题\n",
    "    best_acc = 0                                   #这里看到示例代码中epoch数量比较小，所以就不设置早停了\n",
    "    \n",
    "    #training\n",
    "    epoch = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        epoch_acc = 0\n",
    "        epoch_train_loss = 0\n",
    "        set_size = 0\n",
    "        for x,y in tr_set:\n",
    "            optimizer.zero_grad()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            n_epochs\n",
    "            pred = model(x)\n",
    "            \n",
    "#             print(f'inputs device: {x.device}, labels device: {y.device}')\n",
    "#             print(f'model device: {next(model.parameters()).device}')\n",
    "            \n",
    "            batch_cross_entropy_loss = model.cal_loss(pred, y, config['L2_lambda'])\n",
    "            batch_cross_entropy_loss.backward()\n",
    "            optimizer.step()\n",
    "            #dim (int) – the dimension to reduce.对于具有多个参数的tensor.max()第二个返回值是index\n",
    "            \n",
    "            _,pred_maxProb_class = torch.max(pred, 1)                      #获得每个预测张量中最大概率值的标签\n",
    "\n",
    "            batch_acc = (pred_maxProb_class.detach() == y.detach()).sum().item()       #计算单个batch的acc\n",
    "            epoch_acc += batch_acc\n",
    "            epoch_train_loss += (batch_cross_entropy_loss.detach().cpu().item())*len(x)#len无需将张量分离出来\n",
    "            set_size += len(x)\n",
    "            loss_record['train'].append(batch_cross_entropy_loss.detach().cpu().item())#记录训练损失\n",
    "            acc_record['train'].append(epoch_acc/len(x))\n",
    "            \n",
    "        print(len(tr_set.dataset) == set_size)\n",
    "        \n",
    "        epoch_acc /= len(tr_set.dataset)                   #熟悉这种由batchloss*batchsize->total/trainsize的过程\n",
    "        assert epoch_acc <= 1, 'acc数值异常'\n",
    "        epoch_train_loss /= len(tr_set.dataset)                  #其实是可以不用计算每个训练集epoch的loss的 但是个好习惯\n",
    "        \n",
    "        #validation \n",
    "        if len(dev_set.dataset) > 0:\n",
    "            dev_loss, dev_acc = dev(dev_set,model,device)\n",
    "            loss_record['dev'].append(dev_loss)\n",
    "            acc_record['dev'].append(dev_acc)\n",
    "            #visualization(print loss&acc info)\n",
    "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Dev Acc: {:3.6f} loss: {:3.6f}'\n",
    "                  .format(epoch + 1, n_epochs, epoch_acc, epoch_train_loss, dev_acc, dev_loss))\n",
    "            \n",
    "            #save model everytime acc gets smaller.\n",
    "            if dev_acc > best_acc: \n",
    "                best_acc = dev_acc\n",
    "                torch.save(model.state_dict(),config['save_path'])\n",
    "                print('saving model with the acc of {:.3f}'.format(dev_acc))\n",
    "        else :\n",
    "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n",
    "            epoch + 1, n_epochs, epoch_acc, epoch_train_loss))\n",
    "            \n",
    "            \n",
    "    \n",
    "    # if not validating, save the last epoch，(when small dataset)\n",
    "    if len(dev_set.dataset) == 0:\n",
    "        torch.save(model.state_dict(), config['save_path'])\n",
    "        print('saving model at last epoch') \n",
    "    return best_acc, loss_record, acc_record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af0d668",
   "metadata": {},
   "source": [
    "关于多参数的torch.max用法\n",
    "```python\n",
    "a = torch.randn(4, 4)\n",
    "print(a)\n",
    "torch.max(a, 1) dim:the dim to reduce。由于预测结果的输出是行向量，我们需要得到行上的最大值，假设我们找到了每行的最大值，此时得到了4*1的张量，那么reduce的dim就变成了列，我们找行上的最大值其实是列与列之间进行的比较。所以参数dim=1\n",
    "tensor([[-0.6971,  0.3609, -0.3830,  0.3976],\n",
    "        [ 0.3982, -0.4047, -0.7660, -0.6009],\n",
    "        [-1.7744,  0.7950,  1.1826, -0.3340],\n",
    "        [ 0.4587, -1.7904, -1.5404, -0.2847]])\n",
    "torch.return_types.max(\n",
    "values=tensor([0.4587, 0.7950, 1.1826, 0.3976]),\n",
    "indices=tensor([3, 2, 2, 0]))\n",
    "```\n",
    "# Testing save pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a7110a",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ce281cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    我们需要的是整个验证集的交叉熵损失，但对于每个batch取了平均，所以\n",
    "'''\n",
    "def dev(dev_set, model, device):\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    model.eval()\n",
    "    for x, y in dev_set:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            dev_pred = model(x)\n",
    "            batch_loss = model.cal_loss(dev_pred,y,config['L2_lambda'])\n",
    "        _,max_predProb_class = torch.max(dev_pred, 1)\n",
    "        \n",
    "        total_loss += batch_loss*len(x)\n",
    "        total_acc += (max_predProb_class.detach() == y.detach()).sum().item()\n",
    "        #这里total_acc表示所有验证样本中TP的数量即TruePositive，处理方式与dev_loss相同\n",
    "        \n",
    "    dev_loss = total_loss/len(dev_set.dataset)\n",
    "    dev_acc = total_acc/len(dev_set.dataset)\n",
    "    return dev_loss, dev_acc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a650fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_set, model, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for x in test_set:\n",
    "        x = x.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(x)\n",
    "            _,pred_class = torch.max(pred,1) #得到概率最大得分对应的类别转化为对应index\n",
    "            preds.append(pred.detach().cpu())\n",
    "    preds = torch.cat(preds,dim = 0).numpy()\n",
    "    return preds\n",
    "\n",
    "def save_pred(preds, file):\n",
    "    '''Save predictions to specified file '''\n",
    "    print('Saving results to {}'.format(file))\n",
    "    with open(file, 'w') as fp:\n",
    "        writer.writerow(['Id', 'Class'])\n",
    "        for i, p in enumerate(preds):\n",
    "            writer.writerow([i, p])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa661426",
   "metadata": {},
   "source": [
    "```python\n",
    "#在哪个维度上拼接则保持其他维度不变\n",
    ">>> x = torch.randn(2, 3)\n",
    ">>> x\n",
    "tensor([[ 0.6580, -1.0969, -0.4614],\n",
    "        [-0.1034, -0.5790,  0.1497]])\n",
    ">>> torch.cat((x, x, x), 0)\n",
    "tensor([[ 0.6580, -1.0969, -0.4614],\n",
    "        [-0.1034, -0.5790,  0.1497],\n",
    "        [ 0.6580, -1.0969, -0.4614],\n",
    "        [-0.1034, -0.5790,  0.1497],\n",
    "        [ 0.6580, -1.0969, -0.4614],\n",
    "        [-0.1034, -0.5790,  0.1497]])\n",
    ">>> torch.cat((x, x, x), 1)\n",
    "tensor([[ 0.6580, -1.0969, -0.4614,  0.6580, -1.0969, -0.4614,  0.6580,  -1.0969, -0.4614],\n",
    "        [-0.1034, -0.5790,  0.1497, -0.1034, -0.5790,  0.1497, -0.1034,  -0.5790,  0.1497]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe49222",
   "metadata": {},
   "source": [
    "# Setup Hyper-parameters\n",
    "`config` contains hyper-parameters for training and the path to save your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4071ad2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = get_device()\n",
    "print(device)\n",
    "config = {\n",
    "    'n_epochs':20,\n",
    "    'batch_size':512,\n",
    "    'optimizer':'Adam',\n",
    "    'optim_hparas':{\n",
    "        'lr':0.0001,\n",
    "#         'momentum':0.9,\n",
    "        #'weight_decay': 5e-4,\n",
    "    },\n",
    "    'early_stop':20,\n",
    "    'L2_lambda':5e-4,\n",
    "    'save_path':'models/model.pth',\n",
    "    'feat_dir':'./dataset/libriphone/feat/',\n",
    "    'phone_path':'./dataset/libriphone/'\n",
    "}\n",
    "input_dim = 39\n",
    "concat_nframes = 21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53ece0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3857\n",
      "[Dataset] - # phone classes: 41, number of utterances for train: 3857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3857it [00:23, 163.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train set\n",
      "torch.Size([2379588, 819])\n",
      "torch.Size([2379588])\n",
      "3857\n",
      "[Dataset] - # phone classes: 41, number of utterances for val: 429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "429it [00:02, 181.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val set\n",
      "torch.Size([264570, 819])\n",
      "torch.Size([264570])\n",
      "[Dataset] - # phone classes: 41, number of utterances for test: 1078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1078it [00:08, 120.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] test set\n",
      "torch.Size([646268, 819])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = PrepDataloader('train', config['batch_size'], \n",
    "                            config['feat_dir'], \n",
    "                            config['phone_path'], \n",
    "                            concat_nframes,\n",
    "                            train_ratio = 0.9,\n",
    "                            n_jobs=0)\n",
    "dev_data = PrepDataloader('val', config['batch_size']\n",
    "                          ,config['feat_dir'],\n",
    "                          config['phone_path'],\n",
    "                          concat_nframes,\n",
    "                          train_ratio = 0.9,\n",
    "                          n_jobs=0)\n",
    "\n",
    "test_data = PrepDataloader('test', config['batch_size'],\n",
    "                           config['feat_dir'],\n",
    "                           config['phone_path'],\n",
    "                           concat_nframes,\n",
    "                           train_ratio = 0.9,\n",
    "                           n_jobs=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8db2de-6ca3-4599-b6ae-56667712438c",
   "metadata": {},
   "source": [
    "# 训练过程\n",
    "**由于经验比较少，昨日在第一日实现的时候使用了L2正则化，但是一直没有想到L2正则化仅仅是0.0005这么小的参数就造成了  \n",
    "巨大的影响导致模型甚至经过训练导致在训练集和测试集上的ACC不断变小。现在恢复了正常，再次将L2Reg加上之后看看训练效果：发现  \n",
    "确实是正则化导致的模型表现型太差了，为什么Loss确实在变小但是Acc变小的太剧烈了，**  \n",
    "## 实验结果\n",
    "**未正则化时对于四层神经网络（仅dropout+BatchNormalization）：**\n",
    "<img src=\"NoReg.png\" alt=\"NoReg.png\" width=\"600\">  \n",
    "**正则化时Lambda=0.5对于（同上）：**  \n",
    "<img src=\"L2Reg_lambda5e-1.png\" alt=\"L2Reg_lambda5e-1.png\" width=\"600\">  \n",
    "**正则化时Lambda=0.00005对于（同上）：**\n",
    "懒得放图上来了，反正效果差不多。研究下啥原因"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7ec8e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[001/020] Train Acc: 0.587267 Loss: 1.367863 | Dev Acc: 0.666266 loss: 1.066923\n",
      "saving model with the acc of 0.666\n",
      "True\n",
      "[002/020] Train Acc: 0.653859 Loss: 1.107427 | Dev Acc: 0.694225 loss: 0.971749\n",
      "saving model with the acc of 0.694\n",
      "True\n",
      "[003/020] Train Acc: 0.679154 Loss: 1.017007 | Dev Acc: 0.707635 loss: 0.919838\n",
      "saving model with the acc of 0.708\n",
      "True\n",
      "[004/020] Train Acc: 0.694781 Loss: 0.961401 | Dev Acc: 0.717942 loss: 0.888750\n",
      "saving model with the acc of 0.718\n",
      "True\n",
      "[005/020] Train Acc: 0.705971 Loss: 0.921404 | Dev Acc: 0.724697 loss: 0.866083\n",
      "saving model with the acc of 0.725\n",
      "True\n",
      "[006/020] Train Acc: 0.714782 Loss: 0.890139 | Dev Acc: 0.728907 loss: 0.848969\n",
      "saving model with the acc of 0.729\n",
      "True\n",
      "[007/020] Train Acc: 0.721516 Loss: 0.865919 | Dev Acc: 0.732850 loss: 0.837061\n",
      "saving model with the acc of 0.733\n",
      "True\n",
      "[008/020] Train Acc: 0.727411 Loss: 0.845084 | Dev Acc: 0.736331 loss: 0.828560\n",
      "saving model with the acc of 0.736\n",
      "True\n",
      "[009/020] Train Acc: 0.732608 Loss: 0.827632 | Dev Acc: 0.738194 loss: 0.820260\n",
      "saving model with the acc of 0.738\n",
      "True\n",
      "[010/020] Train Acc: 0.736785 Loss: 0.811707 | Dev Acc: 0.740609 loss: 0.813639\n",
      "saving model with the acc of 0.741\n",
      "True\n",
      "[011/020] Train Acc: 0.740487 Loss: 0.798344 | Dev Acc: 0.741513 loss: 0.810671\n",
      "saving model with the acc of 0.742\n",
      "True\n",
      "[012/020] Train Acc: 0.743855 Loss: 0.786352 | Dev Acc: 0.743433 loss: 0.805963\n",
      "saving model with the acc of 0.743\n",
      "True\n",
      "[013/020] Train Acc: 0.746676 Loss: 0.775591 | Dev Acc: 0.744332 loss: 0.801544\n",
      "saving model with the acc of 0.744\n",
      "True\n",
      "[014/020] Train Acc: 0.749722 Loss: 0.765714 | Dev Acc: 0.745028 loss: 0.800104\n",
      "saving model with the acc of 0.745\n",
      "True\n",
      "[015/020] Train Acc: 0.752039 Loss: 0.757283 | Dev Acc: 0.746751 loss: 0.798258\n",
      "saving model with the acc of 0.747\n",
      "True\n",
      "[016/020] Train Acc: 0.754123 Loss: 0.749124 | Dev Acc: 0.746611 loss: 0.798418\n",
      "True\n",
      "[017/020] Train Acc: 0.756341 Loss: 0.741337 | Dev Acc: 0.746642 loss: 0.796168\n",
      "True\n",
      "[018/020] Train Acc: 0.758249 Loss: 0.734786 | Dev Acc: 0.748070 loss: 0.794109\n",
      "saving model with the acc of 0.748\n",
      "True\n",
      "[019/020] Train Acc: 0.759864 Loss: 0.728064 | Dev Acc: 0.747658 loss: 0.792751\n",
      "True\n",
      "[020/020] Train Acc: 0.761326 Loss: 0.722596 | Dev Acc: 0.748842 loss: 0.791888\n",
      "saving model with the acc of 0.749\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 你的训练代码\n",
    "    model = Classifier(input_dim=input_dim*concat_nframes, output_dim=41, hidden_layers=3, hidden_dim=800).to(device)\n",
    "    best_acc, loss_record, acc_record = train(train_data, dev_data, model, config, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d08686c-60ea-493b-8909-2af633e0e6ef",
   "metadata": {},
   "source": [
    "**经过实验hidden_dim = 1024 concate_nframes = 25时模型表现较佳。由于内存限制，在kaggle上train到epoch = 17时就能够达到  \n",
    "Dev_acc = 0.754953优于较小的hidden_dim.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
